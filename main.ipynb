{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import pickle\n",
    "import yaml\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from timeit import default_timer\n",
    "from einops import rearrange\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from libs.model import Model\n",
    "from libs.utils import *\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/dim96_depth1_iter10_T1_0\n",
      "count_params: 1181763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yhl/anaconda3/envs/torch112/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.3763\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- parameters --------------------------\n",
    "# read the parameters file\n",
    "with open(os.path.join('configs', 'IFactFormer.yml'), 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "config = dict2namespace(config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# create save_dirs\n",
    "i = 0\n",
    "save_dirs = os.path.join(config.log_dir, f'dim{config.model.dim}_depth{config.model.depth}_iter{config.model.n_layer}_T{config.model.in_time_window}_{i}')\n",
    "while os.path.exists(save_dirs):\n",
    "    i += 1\n",
    "    save_dirs = os.path.join(config.log_dir, f'dim{config.model.dim}_depth{config.model.depth}_iter{config.model.n_layer}_T{config.model.in_time_window}_{i}')\n",
    "os.makedirs(save_dirs)\n",
    "print(save_dirs)\n",
    "\n",
    "# copy the parameters file\n",
    "shutil.copyfile('configs/IFactFormer.yml', f'{save_dirs}/IFactFormer.yml')\n",
    "\n",
    "\n",
    "# -------------------------- data_generation --------------------------\n",
    "# data\n",
    "# vor_data: b,t,nx,ny,nz,c, vor_data size is (21,400,32,33,16,4)\n",
    "data = np.load('../../../../../data/turbulent_channel_flow/Re180/Retau180_dim21x400x32x33x16x4_dT200.npy')\n",
    "data = data[0:20, ..., 0:3]\n",
    "data = torch.from_numpy(data).float()\n",
    "\n",
    "input_list = []\n",
    "output_list = []\n",
    "\n",
    "b, t, nx, ny, nz, c = data.shape\n",
    "in_time_window, out_time_window = config.model.in_time_window, 1\n",
    "sample_num = t - (in_time_window + out_time_window)\n",
    "\n",
    "for i in range(b):\n",
    "    for j in range(sample_num):\n",
    "        input_list.append(data[i, j: j + in_time_window, ...])\n",
    "        output_list.append(data[i, j + in_time_window: j + in_time_window + out_time_window, ...])\n",
    "\n",
    "input_data = torch.stack(input_list) # input_data: b t nx ny nz c\n",
    "output_data = torch.stack(output_list) # output_data: b t nx ny nz c\n",
    "\n",
    "output_data = rearrange(output_data, 'b 1 nx ny nz c -> b nx ny nz c')\n",
    "\n",
    "ntrain = int(0.8 * input_data.shape[0])\n",
    "ntest = input_data.shape[0] - ntrain\n",
    "train_x = input_data[:ntrain]\n",
    "train_y = output_data[:ntrain]\n",
    "test_x = input_data[ntrain:]\n",
    "test_y = output_data[ntrain:]\n",
    "\n",
    "norm = {}\n",
    "norm['x_mean'] = torch.mean(train_x, dim=(0,1,2,3,4)).to(device)\n",
    "norm['x_std'] = torch.std(train_x, dim=(0,1,2,3,4)).to(device)\n",
    "norm['y_mean'] = torch.mean(train_y, dim=(0,1,2,3)).to(device)\n",
    "norm['y_std'] = torch.std(train_y, dim=(0,1,2,3)).to(device)\n",
    "\n",
    "energy = torch.sum(data**2, dim=(2,3,4))\n",
    "delta_energy = energy[:,1:,:] - energy[:,:-1,:]\n",
    "delta_energy_max = torch.max(delta_energy.reshape(-1, 3), dim=0).values.to(device)\n",
    "delta_energy_min = torch.min(delta_energy.reshape(-1, 3), dim=0).values.to(device)\n",
    "norm['delta_energy_max'] = delta_energy_max\n",
    "norm['delta_energy_min'] = delta_energy_min\n",
    "with open('norm.pkl', 'wb') as f:\n",
    "    pickle.dump(norm, f)\n",
    "\n",
    "size_lst = [(32,33,16)]\n",
    "length = [4*np.pi, 2, 4*np.pi/3]\n",
    "pos_lst = get_pos_lst(size_lst, length)\n",
    "pos_lst = pos_lst[0]\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_x, train_y), batch_size=config.training.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(test_x, test_y), batch_size=config.training.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# -------------------------- define --------------------------\n",
    "model = Model(config.model).to(device)\n",
    "\n",
    "info = f'count_params: {count_params(model)}'\n",
    "print(info)\n",
    "with open(os.path.join(save_dirs, 'training_epoch_log.txt'), 'a') as file:\n",
    "    file.write(info + '\\n')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.training.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config.training.scheduler_step, gamma=config.training.scheduler_gamma)\n",
    "\n",
    "loss_fn = LpLoss(reduction=False)\n",
    "\n",
    "train_loss_lst = []\n",
    "test_loss_lst = []\n",
    "min_test_loss = 1\n",
    "\n",
    "# -------------------------- training --------------------------\n",
    "t0 = default_timer()\n",
    "for ep in range(config.training.epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    for n_iter, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        y_pred = model((x - norm['x_mean']) / norm['x_std'], pos_lst) * norm['y_std'] + norm['y_mean']\n",
    "        \n",
    "        train_loss = torch.mean(loss_fn(y_pred, y))\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if n_iter % 100 == 0:\n",
    "            print(f'train_loss:{train_loss.item():.4f}')\n",
    "        \n",
    "    train_loss_lst.append(train_loss.item())\n",
    "    scheduler.step()  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        L2 = []\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            y_pred = model((x - norm['x_mean']) / norm['x_std'], pos_lst) * norm['y_std'] + norm['y_mean']\n",
    "            \n",
    "            test_L2 = loss_fn(y_pred, y)\n",
    "            L2.append(test_L2.cpu())\n",
    "            \n",
    "        L2 = torch.mean(torch.cat(L2, dim=0), dim=0)\n",
    "        \n",
    "    t2 = default_timer()\n",
    "    \n",
    "    info = f'{ep} {(t2-t1):.2f} L2:{L2.item():.4f}'\n",
    "    print(info)\n",
    "    with open(os.path.join(save_dirs, 'training_epoch_log.txt'), 'a') as file:\n",
    "        file.write(info + '\\n')\n",
    "        \n",
    "    if min_test_loss > L2:\n",
    "        min_test_loss = L2\n",
    "        torch.save(model.state_dict(), f'{save_dirs}/checkpoint_best.pth')   \n",
    "    torch.save(model.state_dict(), f'{save_dirs}/checkpoint_{ep}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch112",
   "language": "python",
   "name": "torch112"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
